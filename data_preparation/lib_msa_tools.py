import os
import pickle
import subprocess
from Bio import SeqIO
from Bio.Seq import Seq
from collections import defaultdict
from pathlib import Path
from tqdm import tqdm
from typing import Union

def generate_yeast_orthologs_all(inPathDir: Union[str, Path]) -> dict[str, dict[str, str]]:
    '''
    Generate dictionary mapping S. cerevisiae protein to orthologous proteins in its closely-related species. 

    Args:
        inPathDir (Union[str, Path]): Directory of BLAST results. 

    Returns:
        dict[str, dict[str, str]]: A dictionary where key is S. cerevisiae ORF and value is another dictionary. 
                                   The second dictionary maps relative species to the corresponding ortholog in the species. 
    '''
    orthologs = defaultdict(dict)
    for species in ['Sbay', 'Smik', 'Spar','Ncas','Cgla','Agos','Klac','Calb']:
        inPath = inPathDir / ('Scer-' + species + '-blast_stats_coverageCutoff.best.txt')
        with open(inPath, 'r') as f:
            for line in f:
                orthologs[line.split()[0]].setdefault(species.lower(),[]).append((line.split()[1],float(line.split()[2])))
    for scer_orf in orthologs:
        for orth_species in orthologs[scer_orf]:
            (orthologs[scer_orf][orth_species]).sort(key=lambda x: float(x[1]))
            orthologs[scer_orf][orth_species]= orthologs[scer_orf][orth_species][0][0]
    return orthologs

def build_yeast_alignment(extDir: Union[str, Path], 
                          procDir: Union[str, Path], 
                          orthologs: dict[str, dict[str, str]], 
                          outPath: Union[str, Path], 
                          clustalwPath: Union[str, Path]):
    '''
    Generate a combined alignment file contains all the multiple-sequence alignment results. 

    Args:
        extDir (Union[str, Path]): Directory yeast species sequences. 
        procDir (Union[str, Path]): Directory of processed files. 
        orthologs (dict[str, dict[str, str]]): The ortholog dictionary generated by generate_yeast_orthologs_all. 
        outPath (Union[str, Path]): Path to the output file. 
        clustalwPath (Union[str, Path]): Path to ClustalO. 
    '''
    scer_orfs = list(orthologs.keys())
    sequence_dict = read_all_sequence_files(extDir, orthologs)
    fasta_path = write_fasta_MSA_files(procDir, sequence_dict, scer_orfs, orthologs)
    msa_run_clustalw(fasta_path, clustalwPath)
    build_combined_file(procDir, outPath, fasta_path)

def read_all_sequence_files(extData, orthologs):
    """
    Adapted from Pollet and Xia, 2022

    Read NT sequence files from all 6 yeast strains into a dictionary
    ORF names formatted to match the format of the orthologues dictionary
    Args: 
        externalData: path to the folder containing the raw data
    Returns:
        sequences_dict = {strain.xx -> {ORF_name -> [seq]}}
    """
    sequences_dict ={}
    # For each strain, for each ORF update sequences_dict (Sequence dict have all of the ORF sequences for all strains)
    species = list(set([species for d in orthologs.values() for species in list(d.keys())]))
    sequences = ["Scer.aa","Scer.nt"]+[spec+".nt" for spec in species]+[spec+".aa" for spec in species]
    for strain in sequences:
        sequences_dict.update({strain:{}})
        file = SeqIO.parse(open(extData / strain), 'fasta')
        for fasta in file:
            name, sequence = fasta.id, str(fasta.seq)
            # Modify the ORF name to fit the format in the orthologue dictionary
            if strain[:4] =='Scer': 
                name = name
            elif (strain[:4]) in ["Sbay","Smik","Spar"]: # For Sbay, Smik, Spar, switch from ORFN:xxxx to ORFP:xxxx
                s= list(name)
                s[3]='P'
                name= ''.join(s)
            if strain.endswith('.nt'):
                seq = [sequence[i:i+3] for i in range(0, len(sequence), 3)][:-1]
            else:
                seq = [sequence[i:i+3] for i in range(0, len(sequence), 3)]
            sequences_dict[strain].update({name:seq})
    return sequences_dict

def write_fasta_MSA_files(procDir, sequences_dict, Scer_ORFs, orthologs):
    count = 0
    MSADir = procDir / 'MSA'
    species = list(set([species for d in orthologs.values() for species in list(d.keys())]))
    if not MSADir.exists():
        os.makedirs(MSADir)
    testPath = MSADir / Scer_ORFs[0] / (Scer_ORFs[0] + '.aa.fa')
    if not testPath.is_file():
        for ORF in tqdm(Scer_ORFs): 
            if all (k in orthologs[ORF] for k in species):
                file_dir = MSADir / ORF
                if not file_dir.exists():
                    os.makedirs(file_dir)
                outPath_NT = file_dir / (ORF + '.nt.fa')
                outPath_AA = file_dir / (ORF + '.aa.fa')
                species_for_fasta = ["Scer"] + species

                if not outPath_NT.exists():
                    with open(outPath_NT, "w" ) as fout:
                        for spec in species_for_fasta:
                            if spec == 'Scer':
                                ortho_ORF = ORF
                            else:
                                ortho_ORF = orthologs[ORF][spec]
                                if ortho_ORF[0:4] == "ORFP":
                                    ortho_ORF = "ORFN"+ortho_ORF[4:]
                                if ortho_ORF[-4:] == ":pep":
                                    ortho_ORF = ortho_ORF[:-4]
                            seq = sequences_dict[spec+".nt"][ortho_ORF]
                            fout.write(">"+'\t'.join([ortho_ORF, spec + '.nt'])+'\n')
                            fout.write(''.join(seq)+'\n')
                    count = count +1
                if not outPath_AA.exists():
                    with open(outPath_AA, "w" ) as fout:
                        for spec in species_for_fasta:
                            if spec == "Scer":
                                ortho_ORF = ORF
                            else:
                                ortho_ORF = orthologs[ORF][spec]
                            seq = sequences_dict[spec+".aa"][ortho_ORF]
                            fout.write(">"+'\t'.join([ortho_ORF, spec + ".aa"])+'\n')
                            fout.write(''.join(seq)+'\n')
        print ("Fasta files created for ", count," ORFs")
    else:
        print ("Fasta files already created. Skipping.")
    return MSADir

def msa_run_clustalw(MSADir, clustalwPath):
    """ 
    Adapted from Pollet and Xia, 2022

    Run CLUSTALW to generate an MSA from a fasta file
    
    Args: 
        MSADir (str): Path to a directory containing the fasta files
        path_to_clustalo (str): Path to the clustal W executable
    """
    test_ORF = os.listdir(MSADir)[0]
    testPath = MSADir / test_ORF / (test_ORF + ".nt.aln")
    if not testPath.is_file():
        for ORF in tqdm(os.listdir(MSADir)):
            nt_fasta = str(MSADir / ORF / (ORF + ".nt.fa"))
            if not os.path.exists(nt_fasta[:-3]+'.aln'):
                cmd = [str(clustalwPath), '-i', nt_fasta, '-o', nt_fasta[:-3] + '.aln']
                subprocess.run(cmd)
    else:
        print ("CLUSTALW MSA already performed. Skipping.")

    testPath = MSADir / test_ORF / (test_ORF + ".aa.aln")
    if not testPath.is_file():
        for ORF in tqdm(os.listdir(MSADir)):
            aa_fasta = str(MSADir / ORF / (ORF + ".aa.fa"))
            if not os.path.exists(aa_fasta[:-3]+'.aln'):
                cmd = [str(clustalwPath), '-i', aa_fasta, '-o', aa_fasta[:-3] + '.aln']
                subprocess.run(cmd)
    else:
        print ("CLUSTALW MSA already performed. Skipping.")

def build_combined_file(externalData, outPath, MSADir):
    """
    Adapted from Pollet and Xia, 2022
    
    Write a combined alignment file for all ORFs and all species
    
    """
    aligned_seq_dict_pickle = externalData /  'combined_aligned_seq_dict.pkl'

    if not outPath.exists():
        with open(outPath, 'w') as f:
            print ("Writing combined alignment data file")
            combined_dict = {}
            # For each ORF
            for ORF in tqdm(os.listdir(MSADir)):
                if ORF == ".DS_Store":
                    continue
                nt_aln = MSADir / ORF / (ORF + ".nt.aln")
                combined_dict.update({ORF:{}}) # Add ORF as key in combined dict
                parsed_aln = SeqIO.parse(nt_aln, "fasta")
                print(ORF)

                temp = {} # Temporary dict to store the parsed info for this ORF
                for rec in parsed_aln:
                    orf = rec.id
                    description = rec.description.split(' ')[1]
                    strain = description.split('.')[0]
                    sequence = "".join(list(rec.seq))
                    temp.update({(strain,'nt'):sequence})

                # Find indices with gaps in the scer sequence
                gap_indexes = set([i for i, ltr in enumerate(temp['Scer','nt']) if ltr == "-"])
                # Remove position with gaps in Scer from all nt sequences (use map instead?)
                temp['Scer','nt'] = "".join([char for idx, char in enumerate(temp['Scer','nt']) if idx not in gap_indexes])
                temp['Spar','nt'] = "".join([char for idx, char in enumerate(temp['spar','nt']) if idx not in gap_indexes])
                temp['Smik','nt'] = "".join([char for idx, char in enumerate(temp['smik','nt']) if idx not in gap_indexes])
                temp['Sbay','nt'] = "".join([char for idx, char in enumerate(temp['sbay','nt']) if idx not in gap_indexes])
                temp['Ncas','nt'] = "".join([char for idx, char in enumerate(temp['ncas','nt']) if idx not in gap_indexes])
                temp['Cgla','nt'] = "".join([char for idx, char in enumerate(temp['cgla','nt']) if idx not in gap_indexes])
                temp['Agos','nt'] = "".join([char for idx, char in enumerate(temp['agos','nt']) if idx not in gap_indexes])
                temp['Klac','nt'] = "".join([char for idx, char in enumerate(temp['klac','nt']) if idx not in gap_indexes])
                temp['Calb','nt'] = "".join([char for idx, char in enumerate(temp['calb','nt']) if idx not in gap_indexes])

                # Translate scer_nt to get the aa alignment
                scer_aa = Seq(temp['Scer','nt']).translate()
                temp.update({('Scer','aa'):scer_aa})

                if not (len(temp['Scer','aa'])*3 == len(temp['Scer','nt'])==len(temp['Spar','nt'])==len(temp['Smik','nt'])==len(temp['Sbay','nt'])==len(temp['Ncas','nt'])==len(temp['Cgla','nt'])==len(temp['Agos','nt'])==len(temp['Klac','nt'])==len(temp['Calb','nt'])):
                    raise UserWarning('Non-matching lengths when building codon alignment file')

                # Write to the combined_dict and to the summary file
                for key in [('Scer','aa'),('Scer','nt'),('Spar','nt'),('Smik','nt'),('Sbay','nt'),('Ncas','nt'),('Cgla','nt'),('Agos','nt'),('Klac','nt'),('Calb','nt')]: # Forcing the order we want
                    if key[1] == 'aa':
                        sequence = list(temp[key])
                    else:
                        initial = ["".join(temp[key][i:i + 3]) for i in range(0, len(temp[key]), 3)]
                        sequence = [codon if not "-" in codon else "---" for codon in initial] # if gaps in codon change the whole codon to a gap

                    combined_dict[ORF].update({(key[0],key[1]): sequence})
                    f.write(ORF+"\t"+key[0]+"."+key[1]+"\t")
                    f.write("\t".join(sequence))
                    f.write("\n")
                    
            # For testing: if need dictionnary 
            print ("Pickling combined alignment data dictionnary for speed")
            pickle_out = open(aligned_seq_dict_pickle,"wb")
            pickle.dump(combined_dict, pickle_out)
            pickle_out.close()
    
    else:
        print ("Combined alignment data file already exists. Skipping.")
        pickle_in = open(aligned_seq_dict_pickle,"rb")
        combined_dict = pickle.load(pickle_in)
